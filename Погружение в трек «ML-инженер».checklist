   1. Введение

В РЕЗУЛЬТАТЕ ПРОХОЖДЕНИЯ МОДУЛЯ ВЫ:

Img поймёте, кто такой ML-инженер и чем он занимается;

Img от опытного ML-инженера узнаете об особенностях его пути и получите советы по выбору направления в Data Science;

Img изучите кейсы, с которыми вы можете столкнуться в роли ML-инженера, на примере опыта специалиста из сферы;

Img на примере задачи построения рекомендательной системы пройдёте основные этапы работы ML-инженера: от сбора данных и построения модели до оборачивания модели в 
визуальный прототип и его развёртывания на веб-сервере;

Img узнаете, из каких тем состоит образовательная программа трека «ML-инженер» и какие результаты вы получите после их освоения.

Самое главное — вы напишете свой собственный сервер с моделью машинного обучения!

В этом модуле вас также ждёт множество тестов для закрепления знаний и итоговое практическое задание в конце.


 2. Кто такой ML Engineer и чем он занимается


ML Engineer (инженер машинного обучения, ML-инженер) — это специалист по полному циклу разработки моделей машинного обучения, начиная со сбора данных и построения моделей 
и заканчивая написанием бэкенд-сервисов и анализом экспериментов.

Профессия инженера машинного обучения включает в себя ключевые навыки в Data Science. Он решает бизнес-задачи, используя алгоритмы машинного обучения. 
ML-инженер может использовать существующие наработки или каждый раз создавать новые. Его единственная цель — качественное выполнение задачи с наименьшими затратами ресурсов.

В отличие от классического Data Scientist, роль ML Engineer несколько шире:

Data Scientist отвечает за получение значимой информации из данных и построение модели машинного обучения, которая удовлетворяет заданным критериям качества и в 
дальнейшем позволит компании решать необходимые задачи.

ML Engineer занимается не только построением, но и упаковкой модели, её интеграцией (внедрением) в существующую производственную среду и — самое главное — её обслуживанием 
и сопровождением.

Как вы понимаете, для этой специальности важен хороший уровень в Computer Science и знание алгоритмов машинного обучения.

Computer Science (или компьютерные науки) — это наука о методах и процессах сбора, хранения, обработки, передачи, анализа и оценки информации с использованием компьютерных 
технологий, которые обеспечивают возможность её применения для принятия решений.

В России Computer Science называют информатикой, но могут употреблять этот термин по-разному в зависимости от контекста. Подробнее о Computer Science можно прочитать здесь.
(https://blog.skillfactory.ru/glossary/computer-science/)

В разных компаниях функции ML-инженеров могут различаться:

В маленьких компаниях это может быть Full-Stack ML Engineer, который может и найти данные, и проанализировать их, и сделать модель, и выложить её на сервер. 
Иными словами, он может сделать вообще всё, не обладая при этом специализацией в какой-то конкретной области.

В крупных компаниях это может быть более узкий специалист, занимающийся конкретным набором задач, на которых он специализируется: например, построением процесса 
обработки данных на кластере.

Выполняемые рабочие задачи зависят не только от того, в какой компании вы работаете, но и от того, из какой области вы пришли в ML-инженерию. В Data Science 
(в том числе в ML Engineering) можно прийти из любой области и найти способы применения своего предыдущего опыта к новым задачам.

Приведём несколько примеров областей, из которых специалист может прийти в ML Engineering, и покажем, чем он может заниматься.


ПриведЁм несколько примеров, откуда специалист может прийти в ML Engineering и чем он может заниматься:

АНАЛИТИКИ - Первичный анализ данных
РАЗРАБОТЧИКИ ПОАНАЛИТИКИ- Построение пайплайнов – процессов обработки данных, при которых данные проходят через набор разных этапов.
Примерами этапов могут быть выгрузка данных из базы и очистка от ненужной информации.
ЭКОНОМИСТЫ УЧЁНЫЕ - Построение моделей машинного обучения
DEVOPS-Построение систем для выкладки моделей в продакшен и отслеживания их работы. 

Также ML Engineer часто занимается задачами, связанными с Data Engineering.

Data Engineering (инженерия данных) — это практика сбора, хранения и обработки данных. Фокус этого направления состоит в обеспечении надёжности обработки данных.

Специалистов, которые работают в этом направлении, называют инженерами данных или дата-инженерами. Инженеры данных умеют загружать большие объёмы данных в базы, 
настраивать потоки данных между системами и делать так, чтобы расчёты производились быстро и с минимальными затратами вычислительных ресурсов.

КАКИЕ НАВЫКИ МОГУТ БЫТЬ У ML-ИНЖЕНЕРА?

https://lms-cdn.skillfactory.ru/assets/courseware/v1/4fd9bca1d641bcc05cb08af8bfeebbf3/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_2_1.png

По изображению выше можно понять, что есть большое пересечение в навыках между Data Engineer, Software Engineer (разработчик ПО) и Data Scientist.

Когда мы говорили о Fullstack ML Engineer, мы имели в виду некоторое объединение Data Engineer и Data Scientist: такому профессионалу нужно уметь программировать, 
строить модели, оценивать их и выкладывать на сервер, чтобы ими могли пользоваться.

Если говорить о конкретных технологиях стека ML-инженера, то тут всё в основном зависит от компании, в которой он работает, и от того, какими задачами занимается. 
Однако можно выделить несколько классических инструментов, которые наиболее часто встречаются в вакансиях на должность ML-инженера:

Хорошее знание Python, а также библиотек:
для анализа и обработки данных: Numpy, Pandas, Matplotlib, Seaborn, Plotly, Scipy и т. д.;
для машинного и глубокого обучения: Sklearn, TensorFlow/PyTorch, XGBoost, Catboost, LightFM и т. д.;
для упаковки моделей: Pickle, Joblib, ONNX;
для реализации backend-сервисов и деплоя моделей: Flask/Django/Streamlit и т. д.
Математическая база, необходимая для понимания принципов работы моделей машинного обучения.
Навыки работы с базами данных:
знание языка SQL и умение работать с популярными реляционными СУБД (например, PostgreSQL);
умение работать с нереляционными (NoSQL) базами данных (например, ClickHouse, Redis и MongoDB).
Владение инструментами анализа и обработки больших данных: Hadoop, Apache (Kafka, Airflow, Spark).
Владение технологиями контейнеризации и оркестрации: Docker, Docker Compose/Kubernetes.
Умение работать с популярными облачными сервисами и владение облачными вычислениями: Streamlit Cloud/AWS/Microsoft Azure и т. д.
Умение реализовать мониторинг и управление качеством моделей: EKL (ElasticSearch+Logstash+Kibana)/Prometheus+Grafana.
Владение методологией проведения A/B-тестов и проверки бизнес-гипотез.
Владение операционной системой Linux на уровне написания bash-скриптов.

Примеры стеков технологий и требований к ML-инженерам из вакансий на hh.ru:

ML-инженер (middle) от «ЦИАН»
https://lms-cdn.skillfactory.ru/assets/courseware/v1/4428d0819c50d056a3e60f3ba2e84249/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_2_2.png

ML-инженер от «Сбер»
https://lms-cdn.skillfactory.ru/assets/courseware/v1/cade2accfc07dd9847e5e61045e110d2/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_2_3.png

ML-инженер от Go Ahead
https://lms-cdn.skillfactory.ru/assets/courseware/v1/cb7b71a19e5e3c7004fa67d84ecc4c9e/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_2_4.png

ML-инженер рекомендательных систем от «Пульс»
https://lms-cdn.skillfactory.ru/assets/courseware/v1/2e614fa463d7b4e18be6e989a156c95f/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_2_5.png

БИЗНЕС-ЗАДАЧИ ML-ИНЖЕНЕРА

Список задач ML-инженера может быть бесконечным: Data Science, похоже, можно применить где угодно, и эта мысль только подтверждается опытом.

Несмотря на это, есть набор наиболее популярных задач, с большинством из которых вы уже познакомились в процессе прохождения курса.

Отток клиентов
https://lms-cdn.skillfactory.ru/assets/courseware/v1/fff73e840d2beae9fe4e2f63d89f6223/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_2_8.png

Считается, что удержать клиента проще, чем привлечь его. Знание о том, что клиент собирается уйти — очень ценная информация в мире высокой конкуренции и ограниченной 
аудитории потенциальных клиентов. Поэтому мы предпримем какие-то действия, чтобы клиент остался с нами, например дадим ему скидку на наши продукты.

Как получить эту информацию? Есть модели, которые могут это предсказать.

Основные задачи ML-инженера во всех случаях одни и те же: собрать необходимые данные, построить модель, сделать так, чтобы ей можно было пользоваться, то есть реализовать 
сервис, использующий построенную модель.

Скоринг клиентов
https://lms-cdn.skillfactory.ru/assets/courseware/v1/2748cdeec0dbcc8f43831a1e91fc258e/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_2_7.png

Ещё одной важной задачей является скоринг, например кредитный скоринг — это когда на базе кредитной истории человека формируется рейтинг, а уже на его основании принимается 
решение, на каких условиях этому человеку дадут кредит и дадут ли вообще.

Рекомендательные системы
https://lms-cdn.skillfactory.ru/assets/courseware/v1/cfa32341c600129daa360020b8fafa77/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md1_2_6.png

Рекомендательные системы повсеместно используются в интернет-магазинах: покупатель заходит на сайт, выбирает товар, а ему предлагают похожие товары или товары, 
которые заказывали похожие на него люди.

Как это работает? Модель определяет демографический портрет покупателя и смотрит на историю его запросов. Затем она находит похожих на него людей и смотрит, что они искали в
магазине. Эти же товары покажут и целевому покупателю.

Ценообразование
https://lms-cdn.skillfactory.ru/assets/courseware/v1/1d752718a837901036ac062d34a4e512/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_2_9.png

В крупных торговых сетях очень много продуктов. Цена на эти продукты может зависеть от многих факторов: географического положения магазина, демографического портрета т
ипичного покупателя, конкуренции в регионе, скорости поставок и многого другого.

Можно попробовать проанализировать эти параметры вручную. Но если у вас 15 000 магазинов по всей России, задача становится нереальной.

На помощь приходят модели, которые регулярно пересчитывают все эти параметры, анализируют их и делают выводы на их основе.

Какие ещё бывают задачи?

Список можно продолжать бесконечно:

анализ трафика на дорогах и предсказание длительности поездок;
определение стоимости товаров/услуг по объявлениям;
предсказание погоды;
определение болезни по медицинской карте;
предсказание свойств потенциальных лекарств.

Иными словами, сейчас ML-инженер востребован как никогда.

ТЕХНИЧЕСКИЕ ЗАДАЧИ ML-ИНЖЕНЕРА

Как мы уже обсуждали, у ML-инженера в ходе разработки появляется много разных задач. Задачи ML-инженера зависят не только от специфики команды, но и от этапов разработки:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/94f4a0675cdefa22dfcc13e57a16d0d7/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_2_10.png

Говоря простым языком, ML-инженер должен организовать систему, с помощью которой можно будет:

удобно выгружать откуда-то данные;
применять разные трансформации к данным;
загружать изменённые данные в БД, чтобы затем обучать на них модели.

Эта система значительно облегчает моделирование, так как обеспечивает лёгкий доступ к данным и способам работы с ними.

Итак, мы рассмотрели основные особенности специализации ML-инженера, познакомились с перечнем его навыков, обсудили его бизнес- и технические задачи. 
В завершение модуля предлагаем вам прочитать интервью с Юлией Мочаловой(https://trends.rbc.ru/trends/education/628428ba9a79472e7e07f5c4), специалистом по машинному обучению 
в «Газпром-Медиа Дата» и преподавателем SkillFactory, в котором Юлия рассказывает о сути и плюсах профессии, а также о необходимых навыках и перспективах 
профессионального роста ML-инженера.

3. Глазами специалиста


4. Кейс из опыта ML-инженера

Как вы уже могли понять, ML-инженерия включает в себя широкий спектр задач, и потому специалист может столкнуться со множеством разных сложностей. 
Однако Александр Кондрашкин поделится с вами кейсами из практики и советами, которые важны для каждого будущего ML-инженера вне зависимости от специфики сферы. 
Посмотрите видео и ответьте на вопросы ниже.

Как модель предсказания временных рядов может помочь взаимодействию с заказчиком в лице бизнеса?
Отметьте все подходящие варианты ответа.

A-  Через демонстрацию положительного влияния на метрику тех действий, которые были предприняты ранее.

D-  Через её использование в качестве альтернативы А/B-тестированию при невозможности его проведения.

Как определить влияние использования модели на показатели прибыли в случае, если модель внедрена в один из семи сервисов, работающих по одной подписке?

- Высчитать соотношение прибыли по соотношению активности пользователя в сервисах.



5. Разбор кейса ML-инженера: постановка задачи

Ранее мы познакомились с основными особенностями специализации ML-инженер, посмотрели на задачи ML-инженера с точки зрения бизнеса и технической реализации, а 
также изучили профессию с точки зрения практикующего специалиста.

В этом и последующих юнитах мы на примере DS-проекта рассмотрим основные этапы работы ML-инженера и посмотрим на инструменты, которые могут пригодиться.


ОПИСАНИЕ КЕЙСА

Чтобы погрузиться в работу ML-инженера, предлагаем вам вместе с нами создать рекомендательную систему, обернуть её в визуальный прототип сервиса и развернуть его в 
веб-приложении.

Таким образом, мы создадим целое небольшое приложение с графическим интерфейсом, основой которого будет настроенная нами рекомендательная система.

Сложно сразу создать крупный рабочий продукт, поэтому мы начнём работу с построения MVP (Minimum Viable Product) — минимальной жизнеспособной версии, содержащей лишь одну, 
но очень важную для пользователя функциональность, которую мы сможем продемонстрировать нашим руководителям или инвесторам. Для демонстрации работы сервиса мы создадим 
прототип.

За основу возьмём уже рассмотренный нами кейс построения рекомендательной системы книг на основе датасета goodbooks-10k(https://github.com/zygmuntz/goodbooks-10k), 
собранного с сайта Goodreads. Напомним, что данный содержит содержит 6 миллионов рейтингов для 10 тысяч самых популярных книг.

Goodreads — это сайт, на котором люди могут добавлять книги в каталоги, искать их, изучать аннотации и отзывы. Пользователи также могут создавать сообщества, 
в которых они рекомендуют друг другу различную литературу, ведут блоги и устраивают обсуждения.

Для начала немного поговорим о рекомендательных системах в целом и освежим в памяти изученный ранее материал.


РЕКОМЕНДАТЕЛЬНЫЕ СИСТЕМЫ НА ПРАКТИКЕ

Задача построения и использования рекомендательных систем очень сильно отличается от задачи классификации и анализа данных, так как здесь всегда есть пользователь (User), 
для которого вы составляете список рекомендаций.

В условиях продакшена первая проблема, с которой приходится сталкиваться, — это холодный старт (Cold Start). Что рекомендовать человеку, если он только что к вам пришёл? 
Универсального решения пока не придумано. Давайте посмотрим, как решают эту проблему существующие сервисы рекомендаций.

Вариант 1. Просто дать пользователю список самых популярных продуктов.

На первый взгляд, это отличный вариант, однако на самом деле такой подход показывает самые низкие результаты в долгосрочной перспективе.
https://lms-cdn.skillfactory.ru/assets/courseware/v1/551dc7fcb4972dc1e0912ff4cc5372b7/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_5_1.png

Вариант 2. Попросить пользователя при регистрации выбрать несколько интересных ему продуктов из списка, затем создать рекомендации на основании его выбора.

Так работает Netflix с фильмами и сериалами.
https://lms-cdn.skillfactory.ru/assets/courseware/v1/6fb553f942fa6bfc5d044b75a87a3920/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_5_2.jpeg

Вариант 3. Знаменитое «Вместе с этим товаром покупают…», или Content-Based Filtering.
https://lms-cdn.skillfactory.ru/assets/courseware/v1/a498108295587c79c3b967933286dc75/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_5_3.png

Для нашего случая предлагаем использовать подобие последнего варианта, или Content-Based Filtering. Это значит, что пользователь будет заходить на страницу книги, 
а мы будем показывать в блоке рекомендаций похожие книги.

Для построения рекомендаций мы будем использовать гибридные модели, а в качестве инструмента для построения такой модели воспользуемся библиотекой 
LightFM(https://making.lyst.com/lightfm/docs/home.html). Мы уже работали с ней, когда рассматривали модели рекомендательных систем.

Установите библиотеку LightFM, если вы не сделали этого ранее, через команду:

$ pip install lightfm
Мы разобрались, какой тип рекомендаций давать. Осталось ответить на вопрос: как всё это будет работать? Давайте вспомним основные подходы.

ВАРИАНТЫ ИСПОЛЬЗОВАНИЯ РЕКОМЕНДАТЕЛЬНЫХ СИСТЕМ

Онлайн. Обучаем модель, используем её предсказания на новых или старых пользователях.
- Точность, возможность использования с новыми пользователями.
- Затраты на предсказание и обучение.

Офлайн. Один раз обучаем модель и пользуемся результатами. Это значит, что мы обучим модель, сделаем векторизованные представления наших объектов, или эмбеддинги, 
и будем пользоваться ими дальше. Среди всех товаров, представленных в виде векторов, мы найдём наиболее похожие векторы и порекомендуем их пользователю.
- Нет затрат на предсказание во время работы (inference). Можно хранить все рекомендации в базе данных, останутся только затраты на обращение к ней.
- Не можем давать пользователям персонализированные рекомендации.

Мы будем использовать офлайн-модель: её проще обучить и использовать. Несмотря на это, создание такой модели поможет вам в будущем, так как все основные идеи уже будут 
вам знакомы.

Теперь, когда мы обсудили важнейшие детали проекта, настало время переходить к реализации рекомендательной системы.


6. Разбор кейса ML-инженера: построение модели

Ранее мы обсудили контекст задачи. Настало время перейти к построению самой рекомендательной системы.

В скринкасте используется этот ноутбук(https://lms-cdn.skillfactory.ru/assets/courseware/v1/58f4b33dbeb4d4aa28d80724ba86bf2b/asset-v1:SkillFactory+DSPR-2.0+14JULY2021
+type@asset+block/recomendation_system_model.ipynb)  Если вы хотите загрузить готовый рабочий ноутбук на своё устройство или свой Google Диск, вам понадобится папка с 
дополнительными файлами — data. Её можно найти здесь(https://drive.google.com/file/d/1c3HPGxts7sIAoCP2kLDpOggacyt1tF7A/view?usp=share_link).

Также вы можете скачать весь репозиторий проекта на GitHub(https://github.com/SkillfactoryDS/RecomendationSystemOfBooks).

Примечание. Обратите внимание, что при записи скринкаста эксперт не зафиксировал начальное значение генератора случайных чисел (random_state). В приведённом выше ноутбуке 
мы предлагаем везде установить в качестве значения параметра random_state число 42.

Импортируем нужные нам библиотеки и загрузим данные. Создадим папку data и разместим в ней данные. На этом этапе сразу же загрузим инструменты оценки модели 
(метрики ROC AUC, Precision at k и Recall at k)

# Импортируем необходимые модули
import numpy as np
import pandas as pd
import scipy.sparse as sparse
from lightfm import LightFM
from lightfm.cross_validation import random_train_test_split
from lightfm.evaluation import precision_at_k, recall_at_k

# Прочитаем исходные данные
ratings = pd.read_csv('data/ratings.csv')
books = pd.read_csv('data/books.csv')
tags = pd.read_csv('data/tags.csv')
book_tags = pd.read_csv('data/book_tags.csv')

ПРЕДОБРАБОТКА ДАННЫХ

В файле tags.csv очень много неинформативных тегов:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/de40879a5ca4b78c4865a3839484af3a/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_6_1.png

В нашем случае теги сильно влияют на качество модели. Поэтому мы заранее произвели их предобработку:

Выбрали около 500 наиболее популярных тегов.
Сгруппировали оставшиеся теги.
Вот что получилось в итоге:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/da177d60f2f962bed35949c891a79d1d/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_6_2.png

Готовый файл с очищенными тегами, который мы назвали tags_cleaned.csv, лежит в директории data, однако вы также можете скачать его отдельно
здесь(https://lms-cdn.skillfactory.ru/assets/courseware/v1/f8fe012938065d1e01bd7f5b2e8e4b28/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/tags_cleaned.zip).

Вернёмся к датафрейму books. В нём у каждой книги есть два идентификатора, book_id и goodreads_book_id.
https://lms-cdn.skillfactory.ru/assets/courseware/v1/611769a699e1f8b558c824672512f5a5/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_6_3.png

В датафреймах tags и books есть два идентификатора: goodreads_book_id — от сервиса Goodreads и book_id, который привязан к нашей таблице. Создадим словарь, с
помощью которого сможем находить book_id книги по goodreads_book_id.

mapper = dict(zip(books.goodreads_book_id,books.book_id))

Теперь применим этот словарь, чтобы добавить id книги в датафрейм book_tags.

tags = pd.read_csv('data/tags_cleaned.csv')
book_tags = book_tags[book_tags.tag_id.isin(tags.tag_id)]
book_tags['id'] = book_tags.goodreads_book_id.apply(lambda x: mapper[x])

Как вы уже знаете, для работы с моделями в библиотеке LightFM необходимо создать разрежённые матрицы. Для их построения мы будем использовать библиотеку scipy.

Разрежённые матрицы в модуле scipy могут иметь несколько форматов:

- Список координат (Coordinate List, COO) — самый простой способ составления разрежённой матрицы. Согласно этому представлению, компьютер хранит массивы строк и 
столбцов ненулевых значений, а также сами ненулевые значения. В COO данные представлены в виде строка, столбец, значение.

- Cжатое хранение строк (Compressed Sparse Row, CSR) подразумевает подсчёт кумулятивной суммы количества элементов в строке вместо индексов строк.

Примечание. Мы использовали этот способ при составлении разрежённой матрицы в модуле «Рекомендательные системы. Часть II».
https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DSPR-2.0+14JULY2021/jump_to_id/9bbcf507b1b445739d69f2780abea565

- Сжатое хранение столбцов (Compressed Sparse Column, CSС) подразумевает подсчёт кумулятивной суммы количества элементов в столбце.

Примечание. Подробнее узнать о различиях этих форматов можно здесь.(https://python-school.ru/blog/sparse-matrix-scipy/)

Мы будем хранить данные в самом простом формате — COO (координатный формат представления данных). То есть вместо хранения всех значений, которые включают и нулевые, 
мы будем хранить только ненулевые значения и их индексы.

ratings_coo = sparse.coo_matrix((ratings.rating,(ratings.user_id,ratings.book_id)))
feature_ratings  = sparse.coo_matrix(([1]*len(book_tags),(book_tags.id,book_tags.tag_id)))

На этом мы завершаем этап предобработки данных и переходим к этапу построения модели.

ПОСТРОЕНИЕ МОДЕЛИ РЕКОМЕНДАТЕЛЬНОЙ СИСТЕМЫ

Примечание. Из-за большого размера обучающей выборки процесс обучения модели LightFM может занять вплоть до нескольких часов в зависимости от ОС и характеристик компьютера. 
Чтобы не тратить время и сосредоточиться на следующих этапах, вы можете воспользоваться уже обученной нами моделью, сериализованной в формат pickle.

Вы можете скачать модель как отдельный файл здесь(https://drive.google.com/file/d/1zbYFD_ifBMbwauWKryHflRJk94-6hHwR/view?usp=share_link)
или вместе с проектом из GitHub-репозитория(https://github.com/SkillfactoryDS/RecomendationSystemOfBookstemOfBooks).


Вы можете не выполнять код, указанный в этом и следующем разделах, а сразу переходить к разделу добавления эмбеддингов.

Объявим вспомогательные константы для обучения модели:
- NUM_THREADS — число потоков процессора. Параметр зависит от того, на какой операционной системе вы запускаете процесс обучения модели LightFM.

Для Windows и MacOS использование нескольких потоков в LightFM недоступно, поэтому если вы работаете на данных операционных системах, в качестве значения этого 
параметра следует взять 1 (используется только один поток).

- NUM_COMPONENTS — число параметров вектора признаков.

- NUM_EPOCHS — число эпох обучения.

- RANDOM_STATE — число, отвечающее за генерацию случайных чисел (зерно датчика случайных чисел).

# число потоков процессора (зависит от того, на какой машине запускаете)
NUM_THREADS = 8 

#число параметров вектора 
NUM_COMPONENTS = 60 

#число эпох обучения
NUM_EPOCHS = 10

#зерно датчика случайных чисел
RANDOM_STATE = 42

Как мы уже говорили, на этапе создания модели мы используем библиотеку LightFM, чтобы сделать матричное разложение (ALS) рейтингов книг и получить два набора векторов, 
которые будут находиться внутри модели.

Для оценки качества модели ради экономии времени воспользуемся простейшей валидационной схемой — разделением выборки на тренировочную и тестовую. Для этого используем 
функцию random_train_test_split() из библиотеки LightFM.

После разделения выборки на две части создадим модель и обучим её с помощью метода fit().

Итоговый код будет выглядеть так:

#Разбиваем датасет на обучающую и тестовую выборки
train, test = random_train_test_split(ratings_coo, test_percentage=0.2, random_state=RANDOM_STATE)

#Создаём модель
model = LightFM(
    learning_rate=0.05, #темп (скорость) обучения
    loss='warp', #loss-функция
    no_components=NUM_COMPONENTS,#размерность вектора признаков
    random_state=RANDON_STATE #генератор случайных чисел
)

#Обучаем модель
model = model.fit(
    train, #обучающая выборка
    epochs=NUM_EPOCHS, #количество эпох обучения
    num_threads=NUM_THREADS, #количество потоков процессора
    item_features=feature_ratings #признаки товаров (рейтинги книг)
)

Синтаксис очень похож на привычный scikit-learn: первый набор отвечает векторному представлению пользователя, а второй соответствует векторному представлению книг. 
Эти векторы мы будем использовать при составлении эмбедингов.


ТЕСТИРОВАНИЕ МОДЕЛИ

Перед тем как переходить к использованию модели, давайте посмотрим, насколько хорошо она обучилась. Будем использовать наиболее популярные (в рекомендательных системах) 
метрики качества — precision at k и recall at k. Давайте вспомним назначение этих метрик:

precision at k (precision@k) — это отношение количества релевантных предложений в списке рекомендаций к общему количеству предложений, при этом количество предложений равно k.

Что это значит? Допустим, мы делаем 10 рекомендаций и наша метрика precision at 10 равняется 80 %. Это значит, что 80 % наших рекомендаций релевантны для пользователя.

recall at k (recall@k) — это отношение количества релевантных предложений в списке рекомендаций к количеству релевантных предложений в принципе.

Что это значит? Допустим, мы делаем 10 рекомендаций и наша метрика recall at 10 равняется 40 %. Это значит, что если взять все релевантные предложения, то 40 % из них появятся 
в списке наших рекомендаций.

В идеале мы должны стремиться к precision и recall = 1.0. К сожалению, такое практически невозможно, как почти невозможно получить 100 % точность в задачах классификации.

Важно. Плохой precision или плохой recall не означает, что вы получите плохие эмбеддинги. Это следствие того, что модель тренируется через алгоритм ALS, который использует 
другую метрику качества при обучении.

Измерим качество нашей модели, воспользовавшись встроенными в LightFM функциями
precision_at_k() и recall_at_k():

#Тестируем нашу модель
precision_score = precision_at_k(
    model, #модель
    test, #тестовая выборка
    num_threads=NUM_THREADS, #количество потоков процессора
    k=10, #количество предложений
    item_features=feature_ratings #признаки товаров
).mean() #усредняем результаты
 
recall_score = recall_at_k(
    model, #модель
    test, #тестовая выборка
    num_threads=NUM_THREADS, #количество потоков процессора
    k=10, #количество предложений
    item_features=feature_ratings #признаки товаров
).mean() #усредняем результаты

print(recall_score, precision_score)

Результаты получаются неидеальными, однако для тестирования функциональности такого baseline будет достаточно. Вы можете поэкспериментировать с параметрами, 
чтобы добиться других результатов. Однако основная цель нашей работы иная — создать прототип модели, поэтому мы продолжим двигаться в этом направлении, 
и следующим этапом будет добавление эмбеддингов.

Если вы обучали модель самостоятельно, то рекомендуем сохранить её в формате pickle, чтобы впоследствии при перезапуске ноутбука вам не пришлось выполнять обучения заново:
with open('model.pkl', 'wb') as file:
    pickle.dump(model, file, protocol=pickle.HIGHEST_PROTOCOL)



ДОБАВЛЕНИЕ ЭМБЕДДИНГОВ

Переходим к этапу построения рекомендаций.

Примечание. Если вы пропустили этап обучения и тестирования модели, не забудьте десериализовать модель из файла:

with open('model.pkl', 'rb') as file:
    model = pickle.load(file)

Для начала давайте воспользуемся обученной ранее моделью, чтобы получить новые векторные представления книг, которые называются эмбеддингами (embeddings). 
Проще говоря, мы хотим на основе матричного разложения, полученного с помощью нашей модели, представить каждую книгу в виде вектора в некотором пространстве 
размерностью NUM_COMPONENTS.

В нашем случае одной книге соответствует вектор размерности NUM_COMPONENTS = 60 (мы задавали это значение ранее).

# Извлекаем эмбеддинги
item_biases, item_embeddings = model.get_item_representations(features=feature_ratings)

print(item_biases.shape, item_embeddings.shape)
## (10001,) (10001, 60)

Мы получили эмбеддинги — что делать с ними дальше?

Эмбеддинги нужны, чтобы давать предсказание к каждой книге, а точнее искать наиболее похожие.

По сути, нам необходимо среди всего множества векторов, соответствующих книгам, найти ближайшие к заданному. В качестве меры близости можно взять косинусную меру 
(косинус угла между векторами). Напомним, чем меньше значение косинусного расстояния, тем более объекты «похожи» друг на друга:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/90db161e3c1a72b81c4334ecef3c30ae/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_6_4.png

Однако возникает вопрос: как быстрее всего найти среди 10 000 книг наиболее похожую? Не перебирать же их все! На помощь приходит метод ближайших соседей (approximate k-nn), 
который реализован в библиотеке NMSLIB.(https://github.com/nmslib/nmslib)

Non-Metric Space Library (NMSLIB) — это эффективная кроссплатформенная библиотека поиска сходства и инструментарий для оценки методов поиска сходства. Основная библиотека не 
имеет никаких сторонних зависимостей. В последнее время она набирает популярность: например, она стала частью сервиса Amazon Elasticsearch
.(https://aws.amazon.com/about-aws/whats-new/2020/03/build-k-nearest-neighbor-similarity-search-engine-with-amazon-elasticsearch-service/) Подробнее о библиотеке вы можете 
узнать здесь.(https://github.com/nmslib/nmslib)

В основе метода лежит идея о том, что вместо того чтобы перебирать все векторы, мы можем очень быстро обходить граф, каждая вершина которого соответсвует эмбеддингу книги.

Примечание. Мы не будем сейчас затрагивать процесс построения этого графа, который реализуется в библиотеке, вынеся эти тонкости в часть образовательной программы трека 
«ML-инженер». С кратким описанием алгоритма построения и обхода графа вы можете познакомиться в этой статье(https://habr.com/ru/company/vk/blog/338360/). 
Для любознательных — со всеми математическими выкладками библиотеки NMSLIB можно познакомиться в оригинальной статье.(https://arxiv.org/pdf/1508.05470.pdf)

https://lms-cdn.skillfactory.ru/assets/courseware/v1/3a908f9b54a1abdd2fec80da5d9a3be8/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_6_5.png

Перейдём к реализации. Сначала установим библиотеку nmslib:

!pip install nmslib
После установки импортируем её и выполним необходимые преобразования:
- Инициализируем граф для поиска. В терминах библиотеки это называется NMSLIB-индекс. Для инициализации этого объекта используется функция init().
https://nmslib.github.io/nmslib/api.html#nmslib-init Дальнейшие методы вызываются от имени этого объекта.

Примечание. Методика похожа на работу с DataFrame: сначала мы создаём объект класса DataFrame, а затем работаем с ним при помощи методов.

- Добавим на этот граф вершины — наши эмбеддинги. Для этого используем метод addDataPointBatch().
https://nmslib.github.io/nmslib/api.html#nmslib.dist.FloatIndex.addDataPointBatch

- Создадим индекс и сделаем его доступным для поиска. Для этого используется метод createIndex().https://nmslib.github.io/nmslib/api.html#nmslib.dist.FloatIndex.createIndex

import nmslib
 
#Создаём граф для поиска
nms_idx = nmslib.init(method='hnsw', space='cosinesimil')
 
#Начинаем добавлять книги в граф
nms_idx.addDataPointBatch(item_embeddings)
nms_idx.createIndex(print_progress=True)

Теперь давайте напишем вспомогательную функцию для поиска с помощью nmslib. Для этого используется метод knnQuery()
(https://nmslib.github.io/nmslib/api.html#nmslib.dist.FloatIndex.createIndex): он позволяет найти K ближайших соседей вектора 
в индексе (в графе). Для его вызова необходимо указать следующие параметры:

vector — вектор признаков (эмбеддинг), по которому нужно искать похожие книги;
k — количество искомых ближайших соседей (мы возьмём десять).
Метод возвращает кортеж из двух массивов:

ids — массив из идентификаторов ближайших соседей;
distances — массив, элементами которого являются вычисленные расстояния от соседей до заданного вектора.
#Вспомогательная функция для поиска по графу
def nearest_books_nms(book_id, index, n=10):
    nn = index.knnQuery(item_embeddings[book_id], k=n)
    return nn

Давайте протестируем работу поиска рекомендаций на уровне интуиции.

АНАЛИЗ РЕКОМЕНДАЦИЙ ПОСТРОЕННОЙ МОДЕЛИ

Теперь, когда у нас есть функция для поиска десяти наиболее похожих книг, давайте попробуем написать рекомендации к какой-нибудь книге, например к роману «1984» 
Джорджа Оруэлла. Для этого воспользуемся частичным поиском по неполным совпадениям в столбце title. Уберём чувствительность к регистру, приведя оригинальные названия к 
нижнему регистру.

#Отфильтруем только те книги, в которых названии встречается подстрока "1984"
books[books['title'].apply(lambda x: x.lower().find('1984')) >= 0]
https://lms-cdn.skillfactory.ru/assets/courseware/v1/ec13ffdbf4b5f6df51efa0abe811a639/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_6_6.png

Видим, что у нас есть три совпадения, где в названиях встречается "1984".

Давайте возьмём книгу с book_id 846. Это книга, в которую включены повесть «Скотный двор» ("Animal Farm") и роман-антиутопия «1984».

Найдём похожие книги — для этого воспользуемся написанной ранее функцией:
#Вызываем функцию для поиска ближайших соседей
nearest_books_nms(846, nms_idx)
## (array([846,  14,  55,  48, 809,  13, 903, 529, 271, 173]),
## array([0.        , 0.03706956, 0.04132241, 0.06263614, 0.07201874,
##        0.07343107, 0.09369212, 0.09787107, 0.10064054, 0.10802871],
##       dtype=float32))

Как мы говорили ранее, наша функция возвращает кортеж из двух массивов: numpy-вектор идентификаторов и numpy-вектор мер схожести (расстояний) между заданной книгой и 
её ближайшими соседями.

Пока что нас интересуют только идентификаторы— выделим их в отдельную переменную:

#Выделяем идентификаторы рекомендованных книг
nbm = nearest_books_nms(846, nms_idx)[0]
nbm
## array([846,  14,  55,  48, 809,  13, 903, 529, 271, 173])

Примечание. Обратите внимание, что ближайшей к заданной книге всегда будет она сама, поэтому идентификатор этой книги всегда будет первым в списке рекомендаций. 
Пока что мы закроем на это глаза, однако в дальнейшем при разработке прототипа приложения мы исправим этот момент.

Посмотрим на рекомендованные нам книги. Найдём идентификаторы книг, которые находятся в списке nbm:

#Посмотрим на авторов и названия рекомендованных книг
books[books.book_id.isin(nbm)][['authors', 'title']]
https://lms-cdn.skillfactory.ru/assets/courseware/v1/f38e61765d16c85c9a538856d91e4c0c/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_6_7.png

Как можно увидеть, в результатах есть действительно похожие книги. Первыми идут отдельные книги — «1984» и «Скотный двор» ("Animal Farm"). Далее следуют 
«451 градус по Фаренгейту» Рэя Брэдбери ("Fahrenheit 451") и «О дивный новый мир» Олдоса Хаксли ("Brave New World"), которые также являются антиутопиями.

Не забудьте сохранить полученные эмбеддинги — они пригодятся в дальнейшем при реализации прототипа:

with open('item_embeddings.pkl', 'wb') as file:
    pickle.dump(item_embeddings, file, protocol=pickle.HIGHEST_PROTOCOL)
Вы также можете скачать файл с готовыми эмбеддингами 
здесь(https://lms-cdn.skillfactory.ru/assets/courseware/v1/1e7a0935a6b90b0932c40142450a9209/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/item_embeddings.pkl) 
или вместе с проектом из GitHub-репозитория.(https://github.com/SkillfactoryDS/RecomendationSystemOfBooks)

Итак, за пару десятков строк кода мы написали свою рекомендательную систему. Отлично! Следующим этапом будет создание визуального прототипа для нашей модели.


7. Разбор кейса ML-инженера: визуальный прототип

В этом юните мы создадим визуальный прототип нашей модели, основой которого будет небольшое веб-приложение с интерфейсом.

ЗАЧЕМ НУЖЕН ПРОТОТИП?

Представим ситуацию: вы собрали сложную модель и хотите показать результаты её работы заказчику, чтобы он мог принять решение о её внедрении в продакшен. 
Вы приходите на совещание, демонстрируете код на ноутбуке, даже даёте модели какие-то данные и… ничего не происходит.

Чаще всего ставить задачи команде дата-сайентистов будут специалисты из других отраслей (продуктовая команда, маркетинг и так далее). Чтобы суметь донести смысл своей работы, 
получить качественную обратную связь и отследить возможные ошибки перед внедрением модели в продакшен, мы и строим прототипы.

Веб-приложения — один из самых удобных способов представить результаты работы в сфере науки о данных, именно поэтому такой формат является наиболее популярным для реализации 
прототипа. Однако многих специалистов в Data Science, не имеющих опыта веб-разработки, отпугивает идея создания подобных приложений, так как для реализации необходимы некоторые
компетенции.

К счастью для нас, на сегодняшний день создавать наглядные и удобные для использования прототипы можно и без знания HTML, JavaScript, CSS и даже Flask, хотя последнее, 
безусловно, пригодится вам на практике

Например, создавать прототипы можно с помощью фреймворка Streamlit при условии, что вы владеете Python. Streamlit выполняет самую сложную работу по созданию и компоновке 
веб-элементов, позволяя нам заниматься только данными.

ЧТО ТАКОЕ STREAMLIT?

https://lms-cdn.skillfactory.ru/assets/courseware/v1/bbce9d629e686cdf06d2142092ac336d/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_1.png

Streamlit(https://www.streamlit.io/) — это платформа приложений с открытым исходным кодом, созданная специально для DS-проектов. Эта платформа предоставляет Python-фреймворк 
и позволяет быстро строить интерактивный веб-интерфейс, пользуясь готовыми блоками (почти как Tilda для разработки сайтов). Большой плюс этого интерфейса в том, 
что впоследствии его можно загрузить на удалённый сервер, то есть выполнить деплой приложения.

Ниже представлены пример прототипа, написанного на Streamlit, и его отображение на ПК и мобильном устройстве:

Пример десктопного графического интерфейса
https://lms-cdn.skillfactory.ru/assets/courseware/v1/98d59e8bb0afac046a9b49c0bb15d663/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_2_2.png

Пример мобильного графического интерфейса
https://lms-cdn.skillfactory.ru/assets/courseware/v1/8234edd351c2e6561a29216cf50b9957/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_2.png

Для начала установим библиотеку стандартной командой в терминале:
$ pip install streamlit

Проверим версию, чтобы убедиться в успешной установке:
$ streamlit --version

Если вы всё сделали правильно, то с помощью команды ниже сможете запустить демонстрационное приложение, которое покажет разные возможности, предоставляемые Streamlit:
$ streamlit hello

Примечание. По умолчанию веб-сервер streamlit запускается через localhost на порте 8502.
https://lms-cdn.skillfactory.ru/assets/courseware/v1/8a58fb3c206fe9e47e26627bfe562798/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_3_2.png

В результате запуска демонстрационного приложения в вашем браузере откроется окно с примерно следующим интерфейсом:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/3f65194dd761226db6636ee798468805/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_3.png

На данной странице представлены:
- Примеры использования Streamlit — небольшие скрипты, которые показывают возможности библиотеки, такие как анимация, визуализация графиков и интерактивных карт мира, 
работа с таблицами и прочее. Каждый пример сопровождён необходимым для его реализации кодом
- Официальные источники — ссылки на официальный сайт Streamlit, документацию по библиотеке и форум с обсуждением.
- Комплексные примеры проектов — ссылки на репозитории интересных проектов по машинному обучению, интерфейс которых реализован на Streamlit.

Примечание. Рекомендуем вам также познакомиться с примерами шаблонов и приложений(https://streamlit.io/gallery), созданных на форумах Streamlit или в Twitter. 
Попробуйте их, просмотрите их исходный код и получите вдохновение для собственных проектов.
https://lms-cdn.skillfactory.ru/assets/courseware/v1/5d5abd94272220efe87a2d16473cdf08/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_4.png


СОЗДАНИЕ ОСНОВЫ ДЛЯ ПРОТОТИПА

В этом разделе мы реализуем все необходимые для работы приложения вспомогательные функции и глобальные переменные.

Важно. Веб-приложения на Python обычно создаются в файлах формата .py, а не в Jupyter-ноутбуках (.ipynb), так как последние не приспособлены для удобной работы со 
скриптами запуска серверов.

Именно поэтому весь следующий код мы будем писать уже не в ноутбуке, а в файле app.py. Ниже вы можете проследить за поэтапной разработкой кода в этом файле или же скачать его 
здесь(https://lms-cdn.skillfactory.ru/assets/courseware/v1/f10c791e8b7004f616e45a8f99d47f56/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/app_prof.zip) 
или вместе с проектом из GitHub-репозитория(https://github.com/SkillfactoryDS/RecomendationSystemOfBooks).

Импортируем библиотеки для работы с данными:

Файл app.py

#Импортируем необходимые библиотеки
import warnings
warnings.filterwarnings("ignore")

import streamlit as st
import numpy as np
import pandas as pd
import lightfm as lf
import nmslib
import pickle
import scipy.sparse as sparse
import plotly.express as px

Давайте сразу реализуем все необходимые вспомогательные функции. Начнём с функции для чтения файлов, назовём её read_data(). Функция будет возвращать необходимые для 
работы приложения данные в формате pandas.DataFrame. Для построения рекомендаций нам необходимы данные о рейтингах книг и их характеристиках.

Примечание. Здесь и далее "..." означает, что перед представленным фрагментом кода идёт код, который был приведён ранее.

Файл app.py
...
@st.cache
def read_files(folder_name='data'):
    """
    Функция для чтения файлов.
    Возвращает два DataFrame с рейтингами и характеристиками книг.
    """
    ratings = pd.read_csv(folder_name + '/ratings.csv')
    books = pd.read_csv(folder_name + '/books.csv')
    return ratings, books

Новой для нас особенностью этого кода является декоратор st.cache из библиотеки Streamlit. Этот декоратор увеличивает «отзывчивость» приложения и позволяет кэшировать 
полученные ранее данные. Это означает, что при каждом запуске приложения файлы с данными будут читаться лишь один раз, и при последующих обновлениях веб-страницы эта 
операция уже не будет повторяться.

Примечание. Также стоит отметить, что при любом изменении в коде скрипт будет выполняться заново. Важно использовать кэширование, чтобы данные не подгружались 
вновь — это позволит повысить скорость работы сервиса и улучшить пользовательский опыт.

После получения данных нам необходимо организовать возможность сопоставлять элементы из разных таблиц. Для этого создадим функцию make_mappers(). Она будет принимать на 
вход данные о книгах и возвращать два словаря:

- Ключи первого словаря — идентификаторы книг, значения — их названия.
- Ключи второго словаря — идентификаторы книг, значения — их авторы.

Файл app.py

...
def make_mappers(books):
    """
    Функция для создания отображения id в title и authors.
    Возвращает два словаря:
    * Ключи первого словаря — идентификаторы книг, значения — их названия.
    * Ключи второго словаря — идентификаторы книг, значения — их авторы.
    """
    name_mapper = dict(zip(books.book_id, books.title))
    author_mapper = dict(zip(books.book_id, books.authors))

    return name_mapper, author_mapper

Далее создадим функцию load_embeddings() для загрузки векторных представлений книг, которые мы сохранили в предыдущем юните. Данная функция будет читать созданный нами ранее 
файл 'item_embeddings.pkl', затем создавать на основе полученных эмбеддингов индекс (граф) для поиска наиболее похожих (ближайших по метрике косинусного расстояния) книг.

Файл app.py

...
def load_embeddings(file_name='item_embeddings.pkl'):
    """
    Функция для загрузки векторных представлений.
    Возвращает прочитанные эмбеддинги книг и индекс (граф) для поиска похожих книг.
    """
    with open(file_name, 'rb') as f:
        item_embeddings = pickle.load(f)

    # Тут мы используем nmslib, чтобы создать быстрый knn
    nms_idx = nmslib.init(method='hnsw', space='cosinesimil')
    nms_idx.addDataPointBatch(item_embeddings)
    nms_idx.createIndex(print_progress=True)
    return item_embeddings, nms_idx

Затем пойдёт функция для поиска ближайших по метрике расстояния  книг. Думайте об этой функции как о реализации kNN (k-ближайших соседей):

Файл app.py
...
def nearest_books_nms(book_id, index, n=10):
    """
    Функция для поиска ближайших соседей, возвращает построенный индекс.
    Возвращает n наиболее похожих книг и расстояние до них.
    """
    nn = index.knnQuery(item_embeddings[book_id], k=n)
    return nn

Наконец, последняя функция, которая нам понадобится, — функция для составления DataFrame из рекомендованных книг.

Файл app.py

...
def get_recomendation_df(ids, distances, name_mapper, author_mapper):
    """
    Функция для составления таблицы из рекомендованных книг.
    Возвращает DataFrame со столбцами:
    * book_name — название книги;
    * book_author — автор книги;
    * distance — значение метрики расстояния до книги.
    """
    names = []
    authors = []
    #Для каждого индекса книги находим её название и автора
    #Результаты добавляем в списки
    for idx in ids:
        names.append(name_mapper[idx])
        authors.append(author_mapper[idx])
    #Составляем DataFrame
    recomendation_df = pd.DataFrame({'book_name': names, 'book_author': authors, 'distance': distances})
    return recomendation_df

Теперь воспользуемся реализованными нами функциями:

Файл app.py

...
#Загружаем данные
ratings, books = read_files(folder_name='data')
#Создаём словари для сопоставления id книг и их названий/авторов
name_mapper, author_mapper = make_mappers(books)
#Загружаем эмбеддинги и создаём индекс для поиска
item_embeddings, nms_idx = load_embeddings()

Все промежуточные приготовления сделаны. Настало время переходить к написанию графического интерфейса с помощью Streamlit.


СОЗДАНИЕ ВИЗУАЛЬНОЙ ЧАСТИ ПРОТОТИПА

На примере интерфейса нашей рекомендательной системы книг мы рассмотрим основы создания интерфейса веб-приложения, построенного с помощью Streamlit.

Особенностью Streamlit является автоматическое непрерывное обновление интерфейса. Это означает при любом изменении в коде скрипт будет выполняться заново. То есть нам достаточно запустить веб-приложение один раз, а далее мы сможем вносить изменения в его интерфейс «на лету» и отсматривать эти изменения, просто перезагрузив страницу веб-браузера.

Давайте запустим текущую версию приложения — выполним в терминале следующую команду:
$ streamlit run app.py

В результате выполнения команды в вашем браузере должна открыться новая вкладка:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/84f62e8edccc7f87b1ef911e18d204d3/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_5.png


Método 1: Usando o Terminal Integrado do VS Code
Passo a passo:
Abra o VS Code

Abra a pasta do seu projeto:

C:\Users\alexD\Desktop\Data Science\Skillfactory\Блок 9. Профориентация в Data Science\Модуль 2. Погружение в трек «ML-инженер»

Abra o terminal integrado (Ctrl + J)

Execute no terminal:

Método 1: Criar um ambiente com Python 3.11 ou 3.12 (Recomendado)
bash
# Criar novo ambiente com Python 3.11 (mais compatível)
conda create -n meu_projeto python=3.11

# Ativar o ambiente
conda activate meu_projeto

# Instalar as dependências
conda install -c conda-forge streamlit pandas numpy scipy
conda install -c conda-forge nmslib
pip install lightfm plotly


### Comandos úteis do Conda:
- Ver ambientes disponíveis: conda env list
- Instalar pacote: conda install nome_do_pacote
- Salvar ambiente: conda env export > environment.yml

Пока страница веб-приложения пустая — мы будем её заполнять. Однако предварительно необходимо определиться с общей концепцией будущего интерфейса. Воспользуемся 
методикой описания «пользователь — система»:

1. Пользователь входит в приложение и видит:
- название проекта;
- краткое описание проекта и краткую инструкцию по работе с приложением.
2. Пользователь в специальном окне вводит примерное название книги, которая интересует его, например несколько слов из её названия.
3. Система отображает список книг, подходящих под это название (выполняется частичный поиск).
4. Пользователь выбирает из этого списка ту книгу, которая ему нужна.
5. Система предлагает пользователю указать количество необходимых ему рекомендаций.
6. Пользователь указывает количество желаемых рекомендаций — .
7. Система составляет ранжированные рекомендации из  книг, наиболее похожих на ту, которую указал пользователь, и представляет их в удобном формате, например в виде таблицы.

Теперь, когда мы обсудили концепцию прототипа, перейдём к реализации интерфейса, попутно знакомясь с инструментарием библиотеки Streamlit.

Заголовки

Начнём с организационных компонентов приложения, в частности, с заголовков.

Добавим заголовок нашего проекта. Для этого предназначена функция st.title()(https://docs.streamlit.io/library/api-reference/text/st.title),
аргументом которой является текст заголовка.

Файл app.py

...
st.title("Recommendation System Of Books")

Убедимся, что указанный заголовок появился в нашем веб-приложении — для этого просто перезапустим страницу браузера.

В результате мы должны получить примерно следующий вид приложения:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/24168c4d3337745c92a1878e2b6cf9b2/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_6.png

Примечание. Библиотека Streamlit предлагает несколько способов размещения заголовков на веб-странице: например, с помощью функций 
st.header()(https://docs.streamlit.io/library/api-reference/text/st.header)
и st.subheader() (https://docs.streamlit.io/library/api-reference/text/st.subheader)можно добавить дополнительные заголовки на двух разных уровнях. 
Также возможен вариант с применением синтаксиса Markdown для размещения таких заголовков. Для этого используется функция 
st.markdown()(https://docs.streamlit.io/library/api-reference/text/st.markdown).Например:

st.markdown("# Just like a header") — заголовок первого уровня;
st.markdown("## Just like a subheader") — заголовок второго уровня.

Напомним, что с синтаксисом языка разметки Markdown мы знакомились в модуле «*BONUS. Markdown и Git для создания 
портфолио».(https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DSPR-2.0+14JULY2021/jump_to_id/e50b1d5c27b54d19b3c43b196feb72ec)

Текст

Например, мы хотим отобразить в прототипе небольшое описание нашего приложения и инструкцию по работе с ним (текст будем приводить на английском языке, чтобы 
расширить потенциальную аудиторию).

Streamlit предоставляет множество способов отображения текста:

st.text()(https://docs.streamlit.io/library/api-reference/text/st.text) — функция для отображения простого текста;
st.markdown()(https://docs.streamlit.io/library/api-reference/text/st.markdown) — функция для отображения текста в формате Markdown;
st.latex()(https://docs.streamlit.io/library/api-reference/text/st.latex) — функция для отображения текста в формате LaTeX;
st.code()(https://docs.streamlit.io/library/api-reference/text/st.code) — функция для отображения кода с возможностью указания языка программирования.

Мы предлагаем воспользоваться функцией st.markdown()(https://docs.streamlit.io/library/api-reference/text/st.markdown). 
В аргумент этой функции передадим многострочный текст-описание нашего приложения:

Файл app.py
...
st.markdown("""Welcome to the web page of the book recommendation app!
This application is a prototype of a recommendation system based on a machine learning model.

To use the application, you need:
1. Enter the approximate name of the book you like
2. Select its exact name in the pop-up list of books
3. Specify the number of books you need to recommend

After that, the application will give you a list of books most similar to the book you specified""")

Перезагрузим веб-страницу и посмотрим на результат:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/e00bf53526a52f075d2fe8867f7fe3aa/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_7.png

Текстовые виджеты

Для ввода текстовых данных применяются виджеты st.text_input()(https://docs.streamlit.io/library/api-reference/widgets/st.text_input) и 
st.text_area((https://docs.streamlit.io/library/api-reference/widgets/st.text_area)). Их основное различие в том, что первый лучше подходит для короткой текстовой строки, 
а второй — для большого объёма текстовых данных.

Давайте добавим в наш прототип поле для текстового ввода, где пользователь может указать приблизительное название интересующей его книги. Для этого воспользуемся 
функцией st.text_input()(https://docs.streamlit.io/library/api-reference/widgets/st.text_input). В аргументы функции необходимо передать параметр 
label — приветственное сообщение для ввода.

Результат ввода заранее приведём к нижнему регистру для дальнейшего удобства поиска:

Файл app.py

...
# Вводим строку для поиска книг
title = st.text_input('Please enter book name', '')
title = title.lower()

После перезапуска приложения увидим следующее:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/aedf8a6f31b7f72c75896e6e005345e1/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_8.png

Виджеты со множественным выбором

На основе введённого пользователем приблизительного названия книги мы будем производить поиск неполных совпадений среди нашей базы книг. Полученные в 
результате фильтрации названия будут являться элементами некоторого выпадающего списка.

Есть несколько вариантов создания виджетов со множественным выбором для сбора ответов пользователей:
- «переключатель» st.radio():
https://lms-cdn.skillfactory.ru/assets/courseware/v1/126f5ae527fed1eeb4c3741b76b37fed/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_14.gif

- st.selectbox() предоставляет выпадающий список с возможностью выбора из него. Взаимодействие происходит следующим образом:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/1c5aac394ec7a6d224c614a107171848/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_15.gif

- st.multiselect() — для случаев, когда пользователю необходимо ввести несколько выбранных вариантов:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/3b820c181eb459c104c27d95f92f8fdf/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_16.gif

Для нашего прототипа подходит виджет st.selectbox(). Ему необходимо передать два аргумента:

label — приветственная строка;
options — массив из элементов выпадающего списка.
Из выпадающего списка пользователь выбирает нужную ему книгу. Если поле не пустое (результат работы функции st.selectbox() не является None),
будет выводиться текст с указанием выбранной пользователем книги.

Итоговый код будет выглядеть так:

Файл app.py

...
#Выполняем поиск по книгам — ищем неполные совпадения
output = books[books['title'].apply(lambda x: x.lower().find(title)) >= 0]

#Выбор книги из списка
option = st.selectbox("Select the book you need", output['title&#39;].values)

#Проверяем, что поле не пустое
if option:
    #Выводим выбранную книгу
    st.markdown('You selected: "{}"'.format(option))

После перезапуска веб-страницы получим примерно следующее:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/510593c9f1c6103e54e0dad9765ebd4d/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_9.png

Проверьте работу виджетов: наберите в текстовом поле несколько ключевых слов из названий книг, например, "peace", "Anna", "1984" и т. д. В selectbox должны будут
отображаться названия книг, удовлетворяющих вашему запросу.

Числовые виджеты

Далее пользователю предлагается указать количество необходимых ему рекомендаций. Здесь нам понадобятся числовые виджеты:
- st.number_input()(https://docs.streamlit.io/library/api-reference/widgets/st.number_input) предполагает неограниченный ввод путём увеличения счётчика:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/fb16b9b1ffbf02d58065c0c30e5fa9e3/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_17.gif

- st.slider() — ползунок, позволяющий пользователю устанавливать числовой ввод без набора каких-либо данных:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/7257f55b4f4e5616cd834108c335abe0/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_18.gif

Для простоты воспользуемся виджетом st.number_input(). В функцию необходимо передать два аргумента:
- label — приветственная строка;
- min_value — число, используемое по умолчанию.

Пусть по умолчанию ищется десять наиболее похожих книг. Результат, указанное пользователем число, запишем в переменную count_recomendation:

Файл app.py

...
#Проверяем, что поле не пустое
if option:
    ...

    #Указываем количество рекомендаций
    count_recomendation = st.number_input(
        label="Specify the number of recommendations you need",
        value=10
    )  

После перезапуска веб-страницы должно получиться нечто такое:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/a4f7735f71e47090b9cd183bd3902866/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_10.png

Следующий шаг — найти указанное количество наиболее близких книг. Напомним, что для этих целей мы создали функцию nearest_books_nms(). Воспользуемся ей, указав:

book_id — идентификатор книги, которую ввёл пользователь;
index — индексы для реализации поиска;
n — количество интересующих нас рекомендаций.

Примечание. Поскольку ближайшей к искомой книге всегда будет она сама, рекомендовать пользователю ту же книгу, скорее всего, неправильно, поэтому мы отбросим её. 
Тогда, чтобы порекомендовать пользователю n книг, мы должны указать в качестве параметра функции nearest_books_nms n+1 книг (count_recomendation+1):


Файл app.py

...
#Проверяем, что поле не пустое
if option:
    ...

    #Находим count_recomendation+1 наиболее похожих книг
    ids, distances = nearest_books_nms(val_index, nms_idx, count_recomendation+1)
    #Убираем из результатов книгу, по которой производился поиск
    ids, distances = ids[1:], distances[1:]

Таблицы

Теперь у нас есть всё, чтобы отобразить пользователю рекомендации. Давайте представим их в виде таблицы.

Выше мы написали функцию get_recomendation_df(), которая помогает составлять DataFrame из рекомендаций, полученных с помощью kNN-поиска. Воспользуемся ей, указав:
- ids — идентификаторы рекомендованных книг;
- distances — меру расстояния от каждой рекомендации до заданной книги;
- name_mapper и author_mapper — словари для сопоставления id книги и её названия/автора.

После получения DataFrame мы сможем легко отобразить его в интерфейсе. В этом поможет функция 
st.dataframe()(https://docs.streamlit.io/library/api-reference/data/st.dataframe). В её аргументы необходимо передать лишь нужный нам DataFrame:

Файл app.py

...
#Проверяем, что поле не пустое
if option:
    ...

    #Выводим рекомендации к книге
    st.markdown('Most simmilar books are: ')
    #Составляем DataFrame из рекомендаций
    df = get_recomendation_df(ids, distances, name_mapper, author_mapper)
    #Выводим DataFrame в интерфейсе
    st.dataframe(df[['book_name', 'book_author']])

После обновления веб-страницы получим:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/c73906d8769268ee4651bff7213cbd80/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_11.png


Графики

Streamlit нативно поддерживает множество вариаций графиков. Для отображения поддерживаемых элементов используется функция st.write(). Ниже представлено несколько 
примеров оформления функции для отображения графиков из официальной документации Streamlit:

write(mpl_fig) — отображает график Matplotlib (включая Seaborn);
write(altair) — отображает график Altair;
write(graphviz) — отображает граф Graphviz;
write(plotly_fig) — отображает график Plotly;
write(bokeh_fig) — отображает график Bokeh.

Давайте с помощью библиотеки интерактивной визуализации Plotly построим столбчатую диаграмму, которая будет отображать значение косинусного расстояния для каждой 
рекомендованной книги. Столбчатую диаграмму будем строить с помощью функции px.bar() из plotly.expess:

Файл app.py

...
#Проверяем, что поле не пустое
if option:
    ...

    # Строим столбчатую диаграмму
    fig = px.bar(
        data_frame=df,
        x='book_name',
        y='distance',
        hover_data=['book_author'],
        title='Cosine distance to the nearest books'
    )
    # Отображаем график в интерфейсе
    st.write(fig)

После перезагрузки веб-страницы получим следующее:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/40d820ae5a5d827f5e7a620a6d162db5/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_7_12.png

Получается, что Streamlit запустил сервер на нашей локальной машине и мы можем вводить название книг в рекомендательную систему и получать ответ.

Итак, мы создали визуальный прототип для обёртки нашей модели машинного обучения. Для этого мы использовали основные возможности молодого и очень простого в освоении 
фреймворка Streamlit. Как вы уже убедились, их довольно много: одни позволяют вводить числа и текст, другие — делать множественный выбор, третьи — отображать код, 
Markdown и графические элементы. Благодаря этому фреймворку мы можем полностью сосредоточиться на создании контента приложения, а не на реализации его интерфейса, 
что существенно уменьшает время создания прототипа.

На самом деле у Streamlit гораздо больше возможностей. Предлагаем вам ознакомиться со следующими дополнительными материалами по этому фреймворку:
- «Как написать веб-приложение для демонстрации Data Science-проекта на Python»
(https://blog.skillfactory.ru/kak-napisat-veb-prilozhenie-dlya-demonstratsii-data-science-proekta-na-python/)

- «Streamlit для создания интерактивных веб-приложений: начало»
https://medium.com/nuances-of-programming/streamlit
(%D0%B4%D0%BB%D1%8F-%D1%81%D0%BE%D0%B7%D0%B4%D0%B0%D0%BD%D0%B8%D1%8F-%D0%B8%D0%BD%D1%82%D0%B5%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D1%8B%D1%85-%D0%B2%D0%B5%D0%B1-
%D0%BF%D1%80%D0%B8%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9-%D0%BD%D0%B0%D1%87%D0%B0%D0%BB%D0%BE-9e6961877dc9)

- «Python и разработка простого веб-приложения, использующего технологии машинного обучения»
(https://habr.com/ru/company/ruvds/blog/507778/)

Как видите, написать свою модель машинного обучения, а затем обернуть её в визуальный прототип несложно. В качестве дополнительной практики с 
библиотекой Streamlit предлагаем вам самостоятельно поработать с документацией и попробовать улучшить интерфейс приложения: добавить в него изображения, поработать 
с цветами, расположением кнопок и т. д.

Следующим шагом является развёртывание прототипа на сервере. Мы выведем приложение в общий доступ, и вашей рекомендательной системой смогут воспользоваться ваши друзья, 
коллеги и родственники.



8. Разбор кейса ML-инженера: деплой прототипа

Важная особенность работы со Streamlit — возможность развёртывания полученного веб-приложения на сервере с общим доступом. Это делается всего за один клик и несколько минут 
с помощью сервиса Streamlit Cloud.

Streamlit Cloud — это бесплатное рабочее пространство для развёртывания (деплоя) приложений Streamlit, управления и совместной работы над ними.

Для выполнения деплоя достаточно подключить свою учётную запись Streamlit Cloud к своему репозиторию GitHub (общедоступному или частному). После этого Streamlit Cloud 
запускает приложения из кода, который вы сохранили на GitHub. Каждый раз, когда вы обновляете код на GitHub, ваше приложение также будет автоматически обновляться.
Это значительно упрощает разработку и отладку, так что разработчики могут быстро создавать прототипы, исследовать и обновлять приложения.

Как следует из названия, Streamlit Cloud является облачным сервисом, то есть деплой реализуется на стороне удалённого сервера в виде сборки и запуска знакомого нам 
Docker-контейнера.

«Под капотом» Streamlit Cloud выполняет за вас контейнеризацию, аутентификацию, масштабирование, обеспечивает безопасность, что избавляет вас от дополнительных хлопот. 
Streamlit Cloud также даёт возможности для мониторинга приложений, но это отдельная тема, с которой вы при желании можете ознакомиться в документации.

Общая схема работы сервиса выглядит следующим образом:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/25754f962e521b74d65231d3686b266d/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_8_1.png


СОЗДАНИЕ РЕПОЗИТОРИЯ ПРОЕКТА

Для развёртывания приложения на Streamlit Cloud сначала необходимо организовать репозиторий проекта на GitHub.

Примечание. Если вы не хотите или по каким-то причинам не можете загрузить свой вариант прототипа рекомендательной системы на GitHub, мы предлагаем вам сделать форк 
нашего репозитория(https://github.com/SkillfactoryDS/RecomendationSystemOfBooks) и использовать его для деплоя.

Мы уверены, что вы уже умеете загружать проекты на GitHub, однако напомним алгоритм действий (используется режим управления репозиторием в терминале):

Создайте пустой репозиторий проекта на GitHub. Он может быть общедоступным или частным — это не имеет значения.

Создайте файл с зависимостями:
$ pip freeze > requirements.txt

Инициализируйте локальный репозиторий, добавьте все файлы в список отслеживаемых и сделайте коммит:
$ git init
$ git add .
$ git commit -m 'Initial commit'

Свяжите локальный репозиторий с удалённым и сделайте push проекта на GitHub:
$ git branch -M master
$ git remote add origin <ссылка на репозиторий>
$ git push -u origin master

В результате у вас должно получиться примерно следующее содержание репозитория:
https://lms-cdn.skillfactory.ru/assets/courseware/v1/b00bd0b5ca1c38fc88de300a8d6ee59c/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/PROF_md2_8_2.png

































